#+TITLE: Plot values
#+AUTHOR: Ronan-Alexandre Cherrueau
#+EMAIL:  (λx.λy.x@y) Ronan-Alexandre.Cherrueau inria.fr
#+LANGUAGE: en
#+PROPERTY: header-args:python :var exps_url="file:///home/rfish/prog/inria-perso/rsc" :session

# Some configuration variables
# Experiment URL is weather a file or http url, e.g, http://enos.irisa.fr/html/wan

# Doc: https://org-babel.readthedocs.io/en/latest

* Throughput Expectations
See [[http://enos.irisa.fr/html/wan/cpt10/][cpt10-lat*-los0/*.stats]] for raw measures.

#+NAME: throughput-data
#+CAPTION: Throughput Expectations
| Latency (ms) | Throughput (Mbits/s) |
|--------------+----------------------|
|     0.150614 |          9410.991784 |
|    20.000000 |          1206.381685 |
|    50.000000 |           480.173601 |
|   100.000000 |           234.189943 |
|   200.000000 |           115.890071 |

#+NAME: throughput-ref
#+HEADER: :results file
#+BEGIN_SRC python :var throughput_data=throughput-data
import matplotlib
import matplotlib.pyplot as plt

def org_print(str):
    print(str)
    return str

# Accessors to throughput_data
def latency(l):
    return l[0]

def throughput(l):
    return l[1]

matplotlib.rcParams.update({'font.size': 16,
                            'figure.figsize': [8.0, 6.0]})

# Compute values
latencies   = map(latency, throughput_data)    # x
throughputs = map(throughput, throughput_data) # y
img = plt.figure()

# Make plot
plt.plot(latencies, throughputs, '--',
         marker='+', label='Throughput Expectations',
         linewidth=3, markersize=15, color='#FF5722')
plt.xlabel("RTT Latency (ms)")
plt.ylabel("Throughput (Mbits/s)")
plt.legend(loc='upper right')

# Save result
img.savefig('biterate-ref.png')
img.savefig('biterate-ref.pdf')
img.savefig('biterate-ref.svg')

org_print('biterate-ref.svg')
#+END_SRC

#+RESULTS: throughput-ref
[[file:biterate-ref.svg]]


* Latency Impact
Experimentation done during the test are:
#+NAME: experiments-metadata
#+CAPTION: List of Performed Experiments
| Experiment Name              | File                                   | Type           |
|------------------------------+----------------------------------------+----------------|
| Boot & Associate Floating IP | boot-and-associate-floating-ip.yaml    | Rally Nova     |
| Boot & Delete Server         | boot-and-delete.yaml                   | Rally Nova     |
| Boot & Add Sec. Group        | boot-server-and-add-secgroup.yaml      | Rally Nova     |
| Pause & Unpause server       | pause-and-unpause.yaml                 | Rally Nova     |
| Create & Delete Networks     | create-and-delete-networks.yaml        | Rally Neutron  |
| Create & Delete Ports        | create-and-delete-ports.yaml           | Rally Neutron  |
| Create & Delete Routers      | create-and-delete-routers.yaml         | Rally Neutron  |
| Create & Delete Sec. Groups  | create-and-delete-security-groups.yaml | Rally Neutron  |
| Create & Delete Subnets      | create-and-delete-subnets.yaml         | Rally Neutron  |
| L2 Full                      | openstack_full_l2                      | Shaker Neutron |
| L3 Dense East/West           | openstack_dense_l3_east_west           | Shaker Neutron |
| L3 Full East/West            | openstack_full_l3_east_west            | Shaker Neutron |

** Utils                                                           :noexport:
#+NAME: utils-req
#+BEGIN_SRC python :results silent
import requests
import requests_file

# Object to download experiment results
_req = requests.Session()
if exps_url.startswith('file://'):
    _req.mount('file://', requests_file.FileAdapter())

# Accessors to experiments_metadata
def exp_name(l):
    return l[0]

def exp_file(l):
    return l[1]

def is_rally(l):
    return l[2].startswith('Rally')

def is_shaker(l):
    return l[2].startswith('Shaker')

def is_nova(l):
    return l[2].endswith('Nova')

def is_neutron(l):
    return l[2].endswith('Neutron')

# Accessors to *-latencies-perf-data
def perf_mean(l):
    return l[0]

def perf_std(l):
    return l[1]

def perf_error(l):
    return l[2]

def are_nova_perfs(perfs):
    return exp_name(perfs) in map(exp_name, filter(is_nova, experiments_metadata))

def are_l3_perfs(perfs):
    return exp_name(perfs).startswith('L3')
#+END_SRC

** Control Plane Results (Rally)
#+NAME: latency-impact-controlplane-data
#+HEADER: :colnames '("Exp Name" "LAN" "20ms" "50ms" "100ms" "200ms")
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
import numpy as np
import objectpath as op
import operator

def rally_url(exp_name, lat, file):
    """Produces the url to download the json rally report.

    `exp_name` Name of the experiment (as in the url)
    `lat`  is the latency as provided in throughput_data.
    `file` is the json report name, as in `rally-<file>.json`.
    """
    # return "%s/%s/cpt10-lat%s-los0/root/rally_home/rally-%s.json"\
    #        % (exps_url, exp_name, int(lat/2), file)
    return org_print("%s/%s/cpt10-lat%s-los0/root/rally_home/rally-%s.json"\
           % (exps_url, exp_name, int(lat/2), file))

def compute_cp(json):
    "Processes json and computes controle plane values."
    durations = list(op.Tree(json).execute('$..result.duration'))
    mean = np.average(durations)
    std  = np.std(durations)
    errors = list(op.Tree(json).execute('$..result.error'))
    p_errors  = len(filter(operator.truth, errors)) / float(len(errors)) * 100.0
    return  (mean, std, p_errors)

perfs_cp = [ [exp_name(e)] + [ compute_cp(_req.get(rally_url('cpt10', l, exp_file(e))).json())
             for l in map(int, latencies) ]
             for e in experiments_metadata if is_rally(e) ]

# Output results into org
org_print([[perf[0]] + map(lambda p: ("%05.2f, %05.2f, %d" % p), perf[1:]) for perf in perfs_cp])
#+END_SRC

#+RESULTS: latency-impact-controlplane-data
| Exp Name                     | LAN             | 20ms            | 50ms            | 100ms           | 200ms           |
|------------------------------+-----------------+-----------------+-----------------+-----------------+-----------------|
| Boot & Associate Floating IP | 15.48, 02.67, 0 | 17.20, 01.98, 0 | 18.26, 02.35, 0 | 20.63, 02.08, 0 | 25.61, 02.20, 0 |
| Boot & Delete Server         | 15.13, 01.07, 0 | 17.85, 01.53, 0 | 20.34, 00.73, 5 | 23.77, 00.97, 5 | 30.86, 03.26, 0 |
| Boot & Add Sec. Group        | 65.83, 02.03, 0 | 65.55, 01.87, 0 | 66.00, 02.70, 0 | 68.46, 02.02, 0 | 73.57, 03.47, 0 |
| Pause & Unpause server       | 17.25, 00.96, 0 | 19.46, 01.28, 0 | 22.17, 00.90, 0 | 24.62, 01.00, 0 | 28.86, 01.24, 0 |
| Create & Delete Networks     | 01.34, 00.13, 0 | 01.33, 00.10, 0 | 01.31, 00.13, 0 | 01.33, 00.13, 0 | 01.36, 00.13, 0 |
| Create & Delete Ports        | 21.12, 00.64, 0 | 20.92, 00.58, 0 | 21.31, 00.54, 0 | 21.05, 00.76, 0 | 20.99, 00.60, 0 |
| Create & Delete Routers      | 12.00, 00.27, 0 | 11.80, 00.32, 0 | 12.16, 00.38, 0 | 11.98, 00.37, 0 | 11.74, 00.39, 0 |
| Create & Delete Sec. Groups  | 00.66, 00.08, 0 | 00.63, 00.11, 0 | 00.64, 00.12, 0 | 00.66, 00.12, 0 | 00.61, 00.06, 0 |
| Create & Delete Subnets      | 02.96, 00.26, 0 | 03.10, 00.38, 0 | 02.98, 00.34, 0 | 02.92, 00.30, 0 | 02.96, 00.39, 0 |

#+NAME: latency-impact-controlplane-plot
#+HEADER: :export code :results file
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
import matplotlib.pyplot as plt

img = plt.figure()
for p in filter(are_nova_perfs, perfs_cp):
  plt.plot(latencies, map(perf_mean, p[1:]), '--',
           marker='+', label=exp_name(p), linewidth=3,
           markersize=15)

plt.xlabel("RTT Latency (ms)")
plt.legend(loc='center left')
plt.ylabel("Compltetion Time (s)")

img.savefig('latency-impact-cp-nova.png')
img.savefig('latency-impact-cp-nova.pdf')
img.savefig('latency-impact-cp-nova.svg')
org_print('latency-impact-cp-nova.svg')
#+END_SRC

#+RESULTS: latency-impact-controlplane-plot
[[file:latency-impact-cp-nova.svg]]

** Data Plane Results (Shaker)
#+NAME: latency-impact-dataplane-data
#+HEADER: :colnames '("Exp Name" "LAN" "20ms" "50ms" "100ms" "200ms")
#+BEGIN_SRC python
import numpy as np
import objectpath as op

def shaker_url(exp_name, lat, file):
    """Produces the url to download the json shaker report.

    `exp_name` Name of the experiment (as in the url)
    `lat`  is the latency as provided in throughput_data.
    `file` is the json report name, as in `rally-<file>.json`.
    """
    return "%s/%s/cpt10-lat%s-los0/root/shaker_home/%s.json"\
           % (exps_url, exp_name, int(lat/2), file)

def compute_dp(json):
    """Processes shaker json and computes data plane values.

    Computes the mediane and standard derivation of pings of
    bi-directional tests with a concurrency of 1.
    """
    def ping(l):
        "Gets the ping value in json shaker samples table"
        return l[1]
    pings = map(ping, list(op.Tree(json).execute('$..*[@.test is "Bi-directional"' +
                                                 '     and @.concurrency is 1].samples'))[0])
    mean = np.average(pings)
    std    = np.std(pings)
    return (mean, std)

perfs_dp = [ [exp_name(e)] + [ compute_dp(_req.get(shaker_url('cpt10', l, exp_file(e))).json())
             for l in map(int, latencies) ]
             for e in experiments_metadata if is_shaker(e) ]

# Output results into org
org_print([[exp_name(perf)] + map(lambda p: ("%05.2f, %05.2f" % p), perf[1:]) for perf in perfs_dp])
#+END_SRC

#+RESULTS: latency-impact-dataplane-data
| Exp Name           | LAN          | 20ms         | 50ms          | 100ms         | 200ms         |
|--------------------+--------------+--------------+---------------+---------------+---------------|
| L2 Full            | 02.41, 01.14 | 02.24, 01.11 | 02.30, 01.13  | 02.37, 01.12  | 02.42, 01.16  |
| L3 Dense East/West | 06.44, 02.94 | 42.65, 01.93 | 100.30, 00.63 | 200.14, 00.41 | 400.07, 00.29 |
| L3 Full East/West  | 04.69, 01.96 | 43.99, 03.49 | 100.14, 00.43 | 200.09, 00.27 | 400.04, 00.20 |

#+NAME: latency-impact-dataplane-plot
#+HEADER: :export code :results file
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
import matplotlib.pyplot as plt

img = plt.figure()
for p in filter(are_l3_perfs, perfs_dp):
  plt.errorbar(latencies, map(perf_mean, p[1:]), map(perf_std, p[1:]),
               ls='--', marker='+', label=exp_name(p), linewidth=3, markersize=15, capsize=5)

plt.xlabel("RTT Latency (ms)")
plt.legend(loc='lower right')
plt.ylabel("Ping Response Time (ms)")
# plt.title("Bit Rate Reference")

img.savefig('latency-impact-dataplane-l3.png')
img.savefig('latency-impact-dataplane-l3.pdf')
img.savefig('latency-impact-dataplane-l3.svg')
org_print('latency-impact-dataplane-l3.svg')
#+END_SRC

#+RESULTS: latency-impact-dataplane-plot
[[file:latency-impact-dataplane-l3.svg]]


* Lantency Impact on Chameleon
** Control Plane Results (Rally)
#+NAME: chameleon-latency-impact-controlplane-data
#+HEADER: :colnames '("Exp Name" "LAN" "20ms" "50ms" "100ms" "200ms")
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
import numpy as np
import objectpath as op
import operator

def compute_cp(json):
    "Processes json and computes controle plane values."
    durations = list(op.Tree(json).execute('$..result.duration'))
    mean = np.average(durations)
    std  = np.std(durations)
    errors = list(op.Tree(json).execute('$..result.error'))
    p_errors  = len(filter(operator.truth, errors)) / float(len(errors)) * 100.0
    return  (mean, std, p_errors)

perfs_cp = [ [exp_name(e)] + [ compute_cp(_req.get(rally_url('cpt10-chameleon', l, exp_file(e))).json())
             for l in map(int, latencies) ]
             for e in experiments_metadata if is_rally(e) ]

# Output results into org
org_print([[perf[0]] + map(lambda p: ("%05.2f, %05.2f, %d" % p), perf[1:]) for perf in perfs_cp])
#+END_SRC

#+RESULTS: chameleon-latency-impact-controlplane-data
| Exp Name                     | LAN             | 20ms            | 50ms            | 100ms           | 200ms           |
|------------------------------+-----------------+-----------------+-----------------+-----------------+-----------------|
| Boot & Associate Floating IP | 15.61, 02.47, 0 | 17.20, 01.98, 0 | 17.98, 02.77, 0 | 19.70, 01.94, 0 | 23.66, 02.52, 0 |
| Boot & Delete Server         | 16.62, 00.98, 0 | 16.42, 00.69, 0 | 18.50, 01.85, 0 | 21.63, 00.94, 0 | 25.95, 00.90, 0 |
| Boot & Add Sec. Group        | 65.72, 02.04, 0 | 64.82, 02.96, 0 | 65.87, 03.01, 0 | 65.88, 01.87, 0 | 72.39, 03.21, 0 |
| Pause & Unpause server       | 18.43, 01.11, 0 | 18.32, 00.85, 0 | 20.39, 01.37, 0 | 23.25, 01.22, 0 | 27.84, 01.93, 0 |
| Create & Delete Networks     | 01.33, 00.13, 0 | 01.24, 00.15, 0 | 01.34, 00.11, 0 | 01.34, 00.12, 0 | 01.29, 00.13, 0 |
| Create & Delete Ports        | 20.14, 00.84, 0 | 20.12, 01.10, 0 | 19.65, 00.92, 0 | 19.78, 01.09, 0 | 19.62, 01.07, 0 |
| Create & Delete Routers      | 11.76, 00.60, 0 | 11.34, 00.53, 0 | 11.48, 00.50, 0 | 11.18, 00.47, 0 | 11.38, 00.40, 0 |
| Create & Delete Sec. Groups  | 00.58, 00.08, 0 | 00.59, 00.09, 0 | 00.60, 00.10, 0 | 00.61, 00.09, 0 | 00.61, 00.07, 0 |
| Create & Delete Subnets      | 02.80, 00.24, 0 | 02.89, 00.40, 0 | 02.82, 00.41, 0 | 02.70, 00.32, 0 | 02.72, 00.46, 0 |

#+NAME: chameleon-latency-impact-controlplane-plot
#+HEADER: :export code :results file
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
img = plt.figure()
for p in filter(are_nova_perfs, perfs_cp):
  plt.plot(latencies, map(perf_mean, p[1:]), '--',
           marker='+', label=exp_name(p), linewidth=3, markersize=15)

plt.xlabel("RTT Latency (ms)")
plt.legend(loc='center left')
plt.ylabel("Compltetion Time (s)")

img.savefig('chameleon-latency-impact-cp-nova.png')
img.savefig('chameleon-latency-impact-cp-nova.pdf')
img.savefig('chameleon-latency-impact-cp-nova.svg')
org_print('chameleon-latency-impact-cp-nova.svg')
#+END_SRC

#+RESULTS: chameleon-latency-impact-controlplane-plot
[[file:chameleon-latency-impact-cp-nova.svg]]


* Neutron DVR Based Deployment

** Control Plane Results (Rally)
#+NAME: latency-impact-dvr-controlplane-data
| Exp Name                     | LAN | 20ms | 50ms | 100ms | 200ms |
|------------------------------+-----+------+------+-------+-------|
| Boot & Associate Floating IP |     |      |      |       |       |
| Boot & Delete Server         |     |      |      |       |       |
| Boot & Add Sec. Group        |     |      |      |       |       |
| Pause & Unpause server       |     |      |      |       |       |


** Data Plane Results (Shaker)
#+NAME: latency-impact-dvr-dataplane-data
#+HEADER: :colnames '("Exp Name" "Oms" "20ms" "50ms" "100ms" "200ms")
#+BEGIN_SRC python
perfs_dvr_dp = [ [exp_name(e)] + [ compute_dp(_req.get(shaker_url('cpt10-dvr', l, exp_file(e))).json())
                 for l in map(int, latencies) ]
                 for e in experiments_metadata if is_shaker(e) ]

# Output results into org
org_print([[exp_name(perf)] + map(lambda p: ("%05.2f, %05.2f" % p), perf[1:]) for perf in perfs_dvr_dp])
#+END_SRC

#+RESULTS: latency-impact-dvr-dataplane-data
| Exp Name           | Oms          | 20ms         | 50ms         | 100ms        | 200ms        |
|--------------------+--------------+--------------+--------------+--------------+--------------|
| L2 Full            | 02.25, 01.16 | 02.54, 01.21 | 02.45, 01.08 | 02.32, 01.03 | 02.54, 01.19 |
| L3 Dense East/West | 01.29, 00.56 | 01.42, 01.10 | 01.43, 00.53 | 01.30, 00.54 | 01.35, 00.57 |
| L3 Full East/West  | 02.47, 01.12 | 02.23, 01.18 | 02.82, 01.30 | 02.46, 01.19 | 02.44, 01.21 |

#+NAME: latency-impact-dvr-dataplane-plot
#+HEADER: :export code :results file
#+BEGIN_SRC python :var experiments_metadata=experiments-metadata
img = plt.figure()
for p in filter(are_l3_perfs, perfs_dvr_dp):
  plt.errorbar(latencies, map(perf_mean, p[1:]), yerr=map(perf_std, p[1:]),
               ls='--', marker='+', label=exp_name(p), linewidth=3, markersize=15, capsize=5)

plt.xlabel("RTT Latency (ms)")
plt.legend(loc='upper right')
plt.ylabel("Ping Response Time (ms)")
# plt.title("Bit Rate Reference")

img.savefig('latency-impact-dvr-dataplane-l3.png')
img.savefig('latency-impact-dvr-dataplane-l3.pdf')
img.savefig('latency-impact-dvr-dataplane-l3.svg')
org_print('latency-impact-dvr-dataplane-l3.svg')
#+END_SRC

#+RESULTS: latency-impact-dvr-dataplane-plot
[[file:latency-impact-dvr-dataplane-l3.svg]]


* Packet Loss Impact
